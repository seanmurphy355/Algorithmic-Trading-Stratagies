# -*- coding: utf-8 -*-
"""Capstone_Research.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pUIv5AKT1u-AhGK9dKBP6fn_k_25rhbd
"""

!wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/libta-lib0_0.4.0-oneiric1_amd64.deb -qO libta.deb
!wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/ta-lib0-dev_0.4.0-oneiric1_amd64.deb -qO ta.deb
!dpkg -i libta.deb ta.deb
!pip install ta-lib

!pip install yfinance

import talib
import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import yfinance as yf
import tweepy
import re
plt.style.use('fivethirtyeight')

udow = yf.Ticker("UDOW")
ndaq = yf.Ticker("NDAQ")
dji = yf.Ticker("DJI")
rut = yf.Ticker("^RUT")
dusl = yf.Ticker("DUSL")
tqqq = yf.Ticker("TQQQ")

hist_udow = udow.history(period="max")
hist_ndaq = ndaq.history(period="max")
hist_dji = dji.history(period="max")
hist_rut = rut.history(period="max")
hist_dusl = dusl.history(period="max")
hist_tqqq = tqqq.history(period="max")

import nltk
nltk.download('vader_lexicon')

from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA

def buy_sell(signal):
  Buy = []
  Sell = []
  flag = -1
  for i in range(0, len(signal)):
    if signal['MACD'][i] > signal['Signal Line'][i]:
      Sell.append(np.nan)
      if flag != 1:
        Buy.append(signal['Close'][i])
        flag = 1
      else:
        Buy.append(np.nan)
    elif signal['MACD'][i] < signal['Signal Line'][i]:
      Buy.append(np.nan)
      if flag != 0:
        Sell.append(signal['Close'][i])
        flag = 0
      else:
        Sell.append(np.nan)
    else:
      Buy.append(np.nan)
      Sell.append(np.nan)
  return (Buy, Sell)

# MACD Indicator detects changes in momentum and can help identify buy sell locations
def MACD_signal(signal):
  flag = 0
  for i in range(0, len(signal)):
    if signal['MACD'] > signal['Signal Line']:
        flag = 1
    elif signal['MACD'] < signal['Signal Line']:
        flag = -1
    else:
      flag = 0
  return flag

# Relative Strength Index used to identify momentum, market conditions, and
# provide warning for unusual price movements
def RSI_signal(signal):
  flag = 0
  for i in range(0, len(signal)):
    if signal['RSI'] > 70:
        flag = -1
    elif signal['RSI'] < 30:
        flag = 1
    else:
      flag = 0
  return flag

# The momentum indicator is used to determine the strength of a price movement.
# Using crossover strategy with SMA 14
def MOM_signal(signal):
  flag = 0
  for i in range(0, len(signal)):
    if signal['MOM'] > signal['SMA_MOM_14']:
        flag = 1
    elif signal['MOM'] < signal['SMA_MOM_14']:
        flag = -1
    else:
      flag = 0
  return flag

# Bollinger bands provides insight into how an asset typically trades. Here the
# sell point occurs when close prices breaks lower band and buy occurs when
# close breaks upper band

def BB_signal(signal):
  flag = 0
  for i in range(0, len(signal)):
    if signal['Close'] >= signal['BB_upper']:
        flag = 1
    elif signal['Close'] <= signal['BB_lower']:
        flag = -1
    else:
      flag = 0
  return flag

# Exponential Moving Average uses ema12 and ema26 to determine the short term
# outlook and decide when to trade. Also places more weight on newer prices

def EMA_short_term_signal(signal):
  flag = 0
  for i in range(0, len(signal)):
    if signal['EMA12'] > signal['EMA26']:
        flag = 1
    elif signal['EMA12'] < signal['EMA26']:
        flag = -1
    else:
      flag = 0
  return flag

# Exponential Moving Average uses ema50 and ema200 to determine the long term
# outlook and decide when to trade. Also places more weight on newer prices

def EMA_long_term_signal(signal):
  flag = 0
  for i in range(0, len(signal)):
    if signal['EMA50'] > signal['EMA200']:
        flag = 1
    elif signal['EMA50'] < signal['EMA200']:
        flag = -1
    else:
      flag = 0
  return flag

def ADX_signal(signal):
  flag = 0
  for i in range(0, len(signal)):
    if signal['ADX'] > 25 and signal['Plus DI'] > signal['Minus DI']:
        flag = 1
    elif signal['ADX'] < 20 and signal['Plus DI'] < signal['Minus DI']:
        flag = -1
    else:
      flag = 0
  return flag

def AROON_signal(signal):
  flag = 0
  for i in range(0, len(signal)):
    if signal['AROON up'] > signal['AROON down']:
        flag = 1
    elif signal['AROON up'] < signal['AROON down']:
        flag = -1
    else:
      flag = 0
  return flag

hist

# plt.figure(figsize=(12.2, 4.5))
# plt.scatter(hist.index, hist['Buy_Signal_Price'], color="green", label='Buy', marker="^", alpha=1)
# plt.scatter(hist.index, hist['Sell_Signal_Price'], color="red", label='Sell', marker="v", alpha=1)
# plt.plot(hist['Close'], label="Close Price", alpha=0.35)
# plt.title("UDOW")
# plt.xlabel('Date')
# plt.ylabel('Close Price')
# plt.show()

# Sentiment analysis login
auth = tweepy.OAuthHandler("UimvYQzuhGtf1owqgHZFLZz9e", "i4yLVZJhMpVvPR248IVzwtKFYVqM8FN9BitTy9MylV40fFJjL8")
api = tweepy.API(auth)

posts = api.search(q="TSLA", tweet_mode='extended')

tweet_df = pd.DataFrame([tweet.full_text for tweet in posts], columns=['Tweets'])

def cleanTxt(text):
  # removed @mentions
  text = re.sub(r'@[A-Za-z0-9]+', '', text)
  # removeing # sybmol
  text = re.sub(r'#', '', text)
  # remove RT
  text = re.sub(r'RT[\s]+', '', text)
  # remove hyper link
  text = re.sub(r'https?:\/\/\S+', '', text)
  return text

tweet_df['Tweets'] = tweet_df['Tweets'].apply(cleanTxt)
tweet_df

""" 

Volitility
Sentiment Analysis
Historical Price data
Reinforcement NN
Get it working on Lean
Filter down to strongest stock TQQQs *****
Use volitility/Momentum/VXN at Minimum
ADX/AROON
Ratios of different assests run adx on that
Ratios always good to look at




"""

class Data:
  def __init__(self, hist):
    self.hist = hist
    self.update_indicators()
    
  def update_indicators(self):

    # create ema and sma signals
    signal_range = 100
    for i in range(2, signal_range+1, 1):

      self.hist[f'MACD_{i}'], self.hist[f"MACD_signal_{i}"], self.hist[f"MACD_hist_{i}"] = talib.MACD(self.hist.Close, fastperiod=i*1.2, slowperiod=i*1.5, signalperiod=i)
      self.hist[f'RSI_{i}'] = talib.RSI(self.hist.Close, timeperiod=i)
      self.hist[f'MOM_{i}'] = talib.MOM(self.hist.Close, timeperiod=i)
      self.hist[f'BB_upper_{i}'], self.hist[f'BB_middle_{i}'], self.hist[f'BB_lower_{i}'] = talib.BBANDS(self.hist.Close, timeperiod=i)
      self.hist[f'ADX_{i}'] = talib.ADX(self.hist.High, self.hist.Low, self.hist.Close, timeperiod=i)
      self.hist[f'Minus_DI_{i}'] = talib.MINUS_DI(self.hist.High, self.hist.Low, self.hist.Close, timeperiod=i)
      self.hist[f'Plus_DI_{i}'] = talib.PLUS_DI(self.hist.High, self.hist.Low, self.hist.Close, timeperiod=i)
      self.hist[f'AROON_down_{i}'], self.hist[f'AROON_up_{i}'] = talib.AROON(self.hist.High, self.hist.Low, timeperiod=14)



      ema_name = f"EMA_{i}"
      sma_name = f"SMA_{i}"
      sma_mom_name = f"SMA_MOM_{i}"
      
      self.hist[ema_name] = talib.EMA(self.hist.Close, timeperiod=i)
      self.hist[sma_name] = talib.SMA(self.hist.Close, timeperiod=i)
      self.hist[sma_mom_name] = talib.SMA(self.hist[f"MOM_{i}"], timeperiod=i)
    
    self.hist['EMA_200'] = talib.EMA(self.hist.Close, timeperiod=200)
    self.hist['SMA_200'] = talib.SMA(self.hist.Close, timeperiod=200)

    self.hist["Prediction Labels"] = self.create_labels( self.hist, "Close", window_size=14)

    
  def get(self):
    return self.hist
  
  def create_labels(self, df, col_name="Close", window_size=14):
        """
        Data is labeled as per the logic in research paper
        Label code : BUY => 1, SELL => -1, HOLD => 0
        params :
            df => Dataframe with data
            col_name => name of column which should be used to determine strategy
        returns : numpy array with integer codes for labels with
                  size = total-(window_size)+1
        https://towardsdatascience.com/stock-market-action-prediction-with-convnet-8689238feae3
        """

        row_counter = 0
        total_rows = len(df)
        labels = np.zeros(total_rows)
        labels[:] = np.nan
        print("Calculating labels")

        while row_counter < total_rows:
            if row_counter >= window_size - 1:
                window_begin = row_counter - (window_size - 1)
                window_end = row_counter
                window_middle = (window_begin + window_end) // 2

                min_ = np.inf
                min_index = -1
                max_ = -np.inf
                max_index = -1
                for i in range(window_begin, window_end + 1):
                    price = df.iloc[i][col_name]
                    if price < min_:
                        min_ = price
                        min_index = i
                    if price > max_:
                        max_ = price
                        max_index = i
                if max_index == window_middle:
                    labels[window_middle] = -1
                elif min_index == window_middle:
                    labels[window_middle] = 1
                else:
                    labels[window_middle] = 0

            row_counter = row_counter + 1
        return labels

df_udow = Data(hist_udow)
df_ndaq = Data(hist_ndaq)
df_dji = Data(hist_dji)
df_rut = Data(hist_rut)
df_dusl = Data(hist_dusl)
df_tqqq = Data(hist_tqqq)

combined = pd.DataFrame()
combined['UDOW ADX'] = df_udow.get()['ADX']
combined['NDAQ ADX'] = df_ndaq.get()['ADX']
combined['DJI ADX'] = df_dji.get()['ADX']
combined['RUT ADX'] = df_rut.get()['ADX']
combined['DUSL ADX'] = df_dusl.get()['ADX']
combined['TQQQ ADX'] = df_tqqq.get()['ADX']
combined_clean = combined.dropna()

combined_clean

class NeuralNetwork:
    def __init__(self, _input, hidden, output, model=None):
        if model == None:
            self.input_nodes = _input
            self.hidden_nodes = hidden
            self.output_nodes = output
            self.model = self.createModel()
        else:
            self.input_nodes = _input
            self.hidden_nodes = hidden
            self.output_nodes = output
            self.model = model

    def createModel(self, child_weights=None):

        model = tf.keras.Sequential()

        _input_shape = tf.keras.Input(shape=(self.input_nodes,))

        _input = tf.keras.layers.Dense(
            units=self.input_nodes, activation='relu')
        
        hidden = tf.keras.layers.Dense(
            units=self.hidden_nodes, activation='relu')
        
        hidden2 = tf.keras.layers.Dense(
            units=self.hidden_nodes, activation='relu')
        
        output = tf.keras.layers.Dense(
            units=self.output_nodes, activation="sigmoid")
        
        model.add(_input_shape)
        model.add(_input)
        model.add(hidden)
        model.add(hidden2)
        model.add(output)
        if child_weights:
            model.set_weights(child_weights)
        model.summary()
        return model

    def copy(self):
        modelCopy = self.createModel()
        weights = self.model.get_weights()
        weight_copies = weights.copy()
        # for i in range(len(weights)):
        #     weight_copies.append(weights[i].clone())
        modelCopy.set_weights(weight_copies)
        return NeuralNetwork(self.input_nodes, self.hidden_nodes, self.output_nodes, model=modelCopy)

    def predict(self, inputs):
        ys = self.model.predict(inputs)
        return ys
        
    def train(self, X_train, y_train):
      adam = tf.keras.optimizers.Adam(learning_rate=0.001)
      self.model.compile(
                      optimizer=adam,
                      loss='mse'
                      )
      self.model.fit(X_train, y_train, epochs = 100)
    
    def save_weights(self):
        self.model.save_weights("./weights")
    
    def load_weights(self, weights="./weights"):
        self.model.load_weights(weights)

df_udow.get().tail()

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
sc = MinMaxScaler(feature_range=(-1,1))

dataset = df_udow.get()
# dataset['Predict'] = dataset['Close'].shift(1)
dataset = dataset.dropna()

X = dataset.drop(['Prediction Labels'], axis=1)
Y = dataset['Prediction Labels']




x_train, x_test, y_train, y_test = train_test_split(X,Y)

x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)



size = X.count(axis='columns')[0]
brain = NeuralNetwork(size, size*2, 1)

# x_train[0]
dataset.head()

brain.train(x_train, y_train)
x_train, y_train

preds = brain.predict(x_test)
preds = [1 if y>=0.5 else -1 if y <= -0.5 else 0 for y in preds]

scores = brain.model.evaluate(x_test, y_test, verbose=1)

y_train.value_counts()

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

print(classification_report(y_test, preds))
print()
print(confusion_matrix(y_test, preds))
print(accuracy_score(y_test, preds)*100)

sc = MinMaxScaler(feature_range=(-1,1))

dataset = df_tqqq.get()
# dataset['Predict'] = dataset['Close'].shift(1)
dataset = dataset.drop(['Prediction Labels'], axis=1)
dataset = dataset.dropna()

scaled = sc.fit_transform(dataset)

tqqq_pred = brain.predict(scaled)

tqqq_pred = [1 if y>=0.5 else -1 if y <= -0.5 else 0 for y in tqqq_pred]

from collections import Counter
Counter(tqqq_pred)

from google.colab import drive
drive.mount('/content/drive')

brain.model.save_weights("./weights")

brain.model.load_weights("./weights")